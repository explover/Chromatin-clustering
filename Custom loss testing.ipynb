{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras import backend as K\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _KL_loss(centers=None, encoded=None):\n",
    "        if (centers is not None) and (encoded is None):\n",
    "            def KL_loss(encoded_true, encoded_pred):\n",
    "                q_arg_array = [encoded_pred, centers]\n",
    "                q = tf.py_func(_get_q, q_arg_array, tf.float32)\n",
    "#                 q.set_shape([encoded_pred.get_shape()[0], centers.get_shape()[0]])\n",
    "                \n",
    "                f_arg_array = [q]\n",
    "                f = tf.py_func(_get_f, f_arg_array, tf.float32)\n",
    "                \n",
    "                p_arg_array = [q, f]\n",
    "                p = tf.py_func(_get_p, p_arg_array, tf.float32)\n",
    "                \n",
    "                loss = tf.reduce_sum(tf.multiply(p, tf.log(tf.div(p, q))))\n",
    "                print(K.ndim(loss))\n",
    "                return loss\n",
    "            return KL_loss\n",
    "            \n",
    "        elif (encoded is not None) and (centers is None):\n",
    "            def KL_loss(centers_true, centers_pred):\n",
    "                q_arg_array = [encoded, centers_pred]\n",
    "                q = tf.py_func(_get_q, q_arg_array, tf.float32)\n",
    "                q.set_shape([encoded.get_shape()[0], centers_pred.get_shape()[0]])\n",
    "                \n",
    "                f_arg_array = [q]\n",
    "                f = tf.py_func(_get_f, f_arg_array, tf.float32)\n",
    "                f.set_shape(q.get_shape())\n",
    "                \n",
    "                p_arg_array = [q, f]\n",
    "                p = tf.py_func(_get_p, p_arg_array, tf.float32)\n",
    "                p.set_shape(q.get_shape())\n",
    "                \n",
    "                loss = tf.reduce_sum(tf.multiply(p, tf.log(tf.div(p, q))))\n",
    "                print(K.ndim(loss))\n",
    "                return loss\n",
    "            return KL_loss\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Fuck it!\")\n",
    "            print(\"Error. You must pass either centers or encoded but not both.\")\n",
    "            return\n",
    "    \n",
    "def _get_q(encoded, centers):\n",
    "#         encoded, centers = arg_array\n",
    "        cart_products = list(product(enumerate(encoded),\n",
    "                               enumerate(centers)))\n",
    "        q = np.ones(shape=(len(encoded), len(centers))) \n",
    "        q_normich = np.array([sum([(1 + (z - mu) ** 2) ** (-1)\n",
    "                                   for (i, z), (j, mu) in cart_products\n",
    "                                   if i == i_chert]) \n",
    "                              for i_chert, _ in enumerate(encoded)])\n",
    "        for (i, z), (j, mu) in cart_products:\n",
    "            q[i, j] = (1 + (z - mu) ** 2) ** (-1) / q_normich[i]\n",
    "        print(np.isnan(q).any())\n",
    "        q = q.astype(np.float32)\n",
    "        return q\n",
    "#     inp = tf.placeholder(tf.float32)\n",
    "#     _get_q = tf.py_func(_get_q, [inp], tf.float32)\n",
    "            \n",
    "def _get_f(q):\n",
    "#         f = arg_array[0]\n",
    "        f = np.zeros_like(q)\n",
    "        for i, _ in enumerate(q):\n",
    "            f += np.roll(q, i, axis=0)\n",
    "        f = f.astype(np.float32)\n",
    "        return f\n",
    "#     inp = tf.placeholder(tf.float32)\n",
    "#     _get_f = tf.py_func(_get_f, [inp], tf.float32)\n",
    "    \n",
    "def _get_p(q, f):\n",
    "#         q, f = arg_array\n",
    "        # get p_normich, hoole\n",
    "        p_normich_orig = q ** 2 / f\n",
    "        p_normich = np.zeros_like(p_normich_orig)\n",
    "        for j in range(p_normich_orig.shape[1]):\n",
    "            p_normich += np.roll(p_normich_orig, j, axis=1)\n",
    "\n",
    "        p = q ** 2 / f / p_normich\n",
    "        p = p.astype(np.float32)\n",
    "        return p\n",
    "#     inp = tf.placeholder(tf.float32)\n",
    "#     _get_p = tf.py_func(_get_p, [inp], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test fuckin' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    input_data_layer = Input(shape=train_data[0].shape) \n",
    "    input_ones_layer = Input(shape=train_ones[0].shape)\n",
    "    \n",
    "    pointwise = LocallyConnected2D(1, kernel_size=(1, 1), use_bias=False)\n",
    "    pointwise_called = pointwise(input_ones_layer)\n",
    "    pointwise.set_weights(np.reshape(centers, (1, np.product(centers.shape), 1, 1)))\n",
    "    \n",
    "    last = Dense(emb_dim, activation=\"sigmoid\")(input_data_layer)\n",
    "            \n",
    "    model = Model(inputs=[input_data_layer, input_ones_layer], outputs=[last, pointwise_called])\n",
    "    model.compile(optimizer=self.optimizer, \n",
    "                  loss=[self._KL_loss(centers=pointwise_called), self._KL_loss(encoded=last)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_f(q):\n",
    "    f_unstacked = tf.reduce_sum(q, axis=0)\n",
    "    f = tf.stack([f_unstacked for _ in range(batch_size)])\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_p(q, f):\n",
    "    numerator = tf.divide(tf.multiply(q, q), f)\n",
    "    almost_denominator = tf.reduce_sum(numerator, axis=1)\n",
    "    denominator = tf.stack([almost_denominator \n",
    "                            for _ in range(n_clusters)], axis=1)\n",
    "    p = tf.divide(numerator, denominator)\n",
    "    #------------------------------------------\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[1. 2.]\n",
      "  [3. 4.]]]\n",
      "\n",
      "\n",
      "[[[1. 2.]\n",
      "  [1. 2.]]\n",
      "\n",
      " [[3. 3.]\n",
      "  [3. 3.]]\n",
      "\n",
      " [[1. 5.]\n",
      "  [1. 5.]]\n",
      "\n",
      " [[1. 5.]\n",
      "  [1. 5.]]\n",
      "\n",
      " [[3. 4.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[1. 2.]\n",
      "  [1. 2.]]]\n",
      "\n",
      "\n",
      "[[[ 0.  0.]\n",
      "  [-2. -2.]]\n",
      "\n",
      " [[ 2.  1.]\n",
      "  [ 0. -1.]]\n",
      "\n",
      " [[ 0.  3.]\n",
      "  [-2.  1.]]\n",
      "\n",
      " [[ 0.  3.]\n",
      "  [-2.  1.]]\n",
      "\n",
      " [[ 2.  2.]\n",
      "  [ 0.  0.]]\n",
      "\n",
      " [[ 0.  0.]\n",
      "  [-2. -2.]]]\n",
      "\n",
      "\n",
      "[[0. 8.]\n",
      " [5. 1.]\n",
      " [9. 5.]\n",
      " [9. 5.]\n",
      " [8. 0.]\n",
      " [0. 8.]]\n",
      "\n",
      "\n",
      "[[1.         0.11111111]\n",
      " [0.16666667 0.5       ]\n",
      " [0.1        0.16666667]\n",
      " [0.1        0.16666667]\n",
      " [0.11111111 1.        ]\n",
      " [1.         0.11111111]]\n",
      "\n",
      "\n",
      "[[1.1111112  1.1111112 ]\n",
      " [0.6666667  0.6666667 ]\n",
      " [0.26666668 0.26666668]\n",
      " [0.26666668 0.26666668]\n",
      " [1.1111112  1.1111112 ]\n",
      " [1.1111112  1.1111112 ]]\n",
      "\n",
      "\n",
      "q is [[0.9        0.09999999]\n",
      " [0.25       0.75      ]\n",
      " [0.375      0.625     ]\n",
      " [0.375      0.625     ]\n",
      " [0.09999999 0.9       ]\n",
      " [0.9        0.09999999]]\n",
      "\n",
      "\n",
      "f is [[2.9 3.1]\n",
      " [2.9 3.1]\n",
      " [2.9 3.1]\n",
      " [2.9 3.1]\n",
      " [2.9 3.1]\n",
      " [2.9 3.1]]\n",
      "\n",
      "\n",
      "p is [[0.9885827  0.01141732]\n",
      " [0.10616437 0.8938356 ]\n",
      " [0.27788845 0.7221116 ]\n",
      " [0.27788845 0.7221116 ]\n",
      " [0.01302521 0.9869748 ]\n",
      " [0.9885827  0.01141732]]\n",
      "\n",
      "\n",
      "0.3084705\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    batch_size = 6\n",
    "    n_clusters = 2\n",
    "    centers = tf.constant([[1., 2.], [3., 4.]])\n",
    "    centers_stacked = tf.stack([centers for _ in range(batch_size)], axis=0)\n",
    "    \n",
    "    embedded = tf.constant([[1., 2.], [3., 3.], [1., 5.], [1., 5.], [3., 4.], [1., 2.]])\n",
    "    embedded_stacked = tf.stack([embedded for _ in range(n_clusters)], axis=1)\n",
    "    \n",
    "    q = tf.subtract(embedded_stacked, centers_stacked)\n",
    "    q_sqr = tf.multiply(q, q)\n",
    "    q_normed_sqr = tf.reduce_sum(q_sqr, axis=2)\n",
    "    ones = tf.ones_like(q_normed_sqr)\n",
    "    \n",
    "    numerator = tf.divide(ones, tf.add(ones, q_normed_sqr))\n",
    "    \n",
    "    almost_denominator = tf.reduce_sum(numerator, axis=1)\n",
    "    denominator = tf.stack([almost_denominator for _ in range(2)], axis=1)\n",
    "    \n",
    "    true_q = tf.divide(numerator, denominator)\n",
    "    \n",
    "#     keks_normed = tf.norm(keks, ord=\"euclidean\", axis=2)\n",
    "#     keks_normed_sqr = tf.multiply(keks_normed, keks_normed)\n",
    "\n",
    "    f = _get_f(true_q)\n",
    "    p = _get_p(true_q, f)\n",
    "    loss = tf.reduce_sum(tf.multiply(p, tf.log(tf.divide(p, true_q))))\n",
    "    \n",
    "    print(centers_stacked.eval(), end=\"\\n\\n\\n\")\n",
    "    print(embedded_stacked.eval(), end=\"\\n\\n\\n\")\n",
    "\n",
    "    print(q.eval(), end=\"\\n\\n\\n\")\n",
    "    print(q_normed_sqr.eval(), end=\"\\n\\n\\n\")\n",
    "    print(numerator.eval(), end=\"\\n\\n\\n\")\n",
    "    print(denominator.eval(), end=\"\\n\\n\\n\")\n",
    "    print(\"q is\", true_q.eval(), end=\"\\n\\n\\n\")\n",
    "    print(\"f is\", f.eval(), end=\"\\n\\n\\n\")\n",
    "    print(\"p is\", p.eval(), end=\"\\n\\n\\n\")\n",
    "    print(loss.eval(), end=\"\\n\\n\\n\")\n",
    "    \n",
    "#     print(keks.eval().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 3],\n",
       "       [4, 7]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(table, (3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
